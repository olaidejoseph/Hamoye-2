{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Acc_91.8_.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olaidejoseph/Hamoye-2/blob/master/Acc_91_8_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGZZzEnGRlbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/My Drive/Kaggle\""
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpMX2_dRxRHD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a0d60edf-660c-4c13-9e70-5ccfbeb3c2ce"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0rpTnJ6R9BY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "170b5b85-20fa-4b2e-e1de-17cf3f71cf13"
      },
      "source": [
        "! ls"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\t\t\t\t     sample_data\n",
            "Kaggle-planet-test-tif.torrent\t     sample_submission_v2.csv\n",
            "Kaggle-planet-test-tif.torrent.zip   sample_submission_v2.csv.zip\n",
            "Kaggle-planet-train-tif.torrent      test_v2_file_mapping.csv\n",
            "Kaggle-planet-train-tif.torrent.zip  train_v2.csv\n",
            "planets-dataset.zip\t\t     train_v2.csv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-8m5L9lR_dO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import gc\n",
        "import cv2\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.optimizers import SGD, RMSprop, Adam \n",
        "from keras.utils import np_utils\n",
        "from keras.layers.core import Dropout\n",
        "\n",
        "# If you would like to make further imports from tensorflow, add them here\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, Conv2D, MaxPool2D, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import os\n",
        "import zipfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import  Sequential, Model"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwIJGD_JUnv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!kaggle competitions download -c planet-understanding-the-amazon-from-space"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPFgVwmeUv-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!kaggle datasets download -d nikitarom/planets-dataset"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0zHVAgFVBAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQySxb-_aug6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv('train_v2.csv')"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h4_52b1bPB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test = pd.read_csv('sample_submission_v2.csv')"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_LEBspTHss9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = df_train[:40479-4500]\n",
        "val_data = df_train[40479-4500:]"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df7tN-BJaj2v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ee86be2d-a7f9-4a49-dc96-eeb157d2e40e"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "y_train = []\n",
        "\n",
        "\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "labels = list(set(flatten([l.split(' ') for l in df_train['tags'].values])))\n",
        "\n",
        "label_map = {l: i for i, l in enumerate(labels)}\n",
        "inv_label_map = {i: l for l, i in label_map.items()}\n",
        "\n",
        "for f, tags in tqdm(df_train.values, miniters=1000):\n",
        "    targets = np.zeros(17)\n",
        "    for t in tags.split(' '):\n",
        "        targets[label_map[t]] = 1 \n",
        "    y_train.append(targets)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40479/40479 [00:00<00:00, 286968.58it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4Riai8KahyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np.array(y_train, np.uint8)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl5m299_IJjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train1 = y_train[:40479-4500]\n",
        "y_val = y_train[40479-4500:]\n",
        "y_train = y_train1"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPGN7FYI2Nf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a function that returns an infinitely looping generator for the train set\n",
        "\n",
        "\n",
        "def get_generator_cyclic(features, labels, batch_size=1):\n",
        "  while True:\n",
        "    for n in range(len(features)//batch_size):\n",
        "      sd = []\n",
        "      for e in train_data['image_name'][n*batch_size:(n+1)*batch_size]:\n",
        "        img = cv2.imread('/content/planet/planet/train-jpg/{}.jpg'.format(e))\n",
        "        sd.append(cv2.resize(img, (299,299)))\n",
        "      cd = np.array(sd, np.float32)/255.\n",
        "      yield (cd, labels[n*batch_size: (n+1)*batch_size])\n",
        "      sd = []\n",
        "  \n"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG-DLlNA5jEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zx = get_generator_cyclic(train_data, y_train, batch_size=128)"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKG6uaLJSOgZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a function that returns an infinitely looping generator for the validation set\n",
        "\n",
        "\n",
        "def get_valgenerator_cyclic(features, labels, batch_size=1):\n",
        "  while True:\n",
        "    for n in range(len(features)//batch_size):\n",
        "      sd = []\n",
        "      for e in val_data['image_name'][n*batch_size:(n+1)*batch_size]:\n",
        "        img = cv2.imread('/content/planet/planet/train-jpg/{}.jpg'.format(e))\n",
        "        sd.append(cv2.resize(img, (299,299)))\n",
        "      cd = np.array(sd, np.float32)/255.\n",
        "      yield (cd, labels[n*batch_size: (n+1)*batch_size])\n",
        "      sd = []\n",
        "  "
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OajVHO2gSiTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valzx = get_valgenerator_cyclic(val_data, y_val, batch_size=128)"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn6N2-6fQKXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a function that returns an infinitely looping generator for the test set \n",
        "\n",
        "def get_test_generator_cyclic(features, batch_size=1):\n",
        "  while True:\n",
        "    for n in range(len(df_test['image_name'].iloc[:40669])//batch_size):\n",
        "      sd = []\n",
        "      for e in df_test['image_name'].iloc[:40669][n*batch_size:(n+1)*batch_size]:\n",
        "        img = cv2.imread('/content/planet/planet/test-jpg/{}.jpg'.format(e))\n",
        "        sd.append(cv2.resize(img, (299,299)))\n",
        "      cd = np.array(sd, np.float32)/255.  \n",
        "      yield (cd)\n",
        "      sd = []\n",
        "    for ni in range(len(df_test['image_name'].iloc[:40669])//batch_size):\n",
        "      sa = []\n",
        "      for w in df_test['image_name'].iloc[40669:][ni*batch_size:(ni+1)*batch_size]:\n",
        "        img2 = cv2.imread('/content/test-jpg-additional/test-jpg-additional/{}.jpg'.format(w))\n",
        "        sa.append(cv2.resize(img2, (299,299)))      \n",
        "      cds = np.array(sa, np.float32)/255.\n",
        "      yield (cds)\n",
        "      sa = []"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFESD-9EQb9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testzz1 = get_test_generator_cyclic(df_test, batch_size=128)"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzMmqNtiYsVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "base_model = tf.keras.applications.InceptionResNetV2(\n",
        "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
        "    input_shape=(299, 299, 3),\n",
        "    include_top=False)  # Do not include the ImageNet classifier at the top."
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ-3SEcddBST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtMBrwFNdEEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = Input(shape=(299, 299, 3))\n",
        "# We make sure that the base_model is running in inference mode here,\n",
        "# by passing `training=False`. This is important for fine-tuning, as you will\n",
        "# learn in a few paragraphs.\n",
        "x = base_model(inputs, training=False)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.25)(x)\n",
        "# A Dense classifier with (multilabel classification)\n",
        "outputs = Dense(17, activation='sigmoid')(x)\n",
        "model = Model(inputs, outputs)"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Dh4zalCd5xC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend\n",
        "\n",
        "\n",
        "def fbeta(y_true, y_pred, beta=2):\n",
        "\t# clip predictions\n",
        "\ty_pred = backend.clip(y_pred, 0, 1)\n",
        "\t# calculate elements\n",
        "\ttp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=1)\n",
        "\tfp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\n",
        "\tfn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis=1)\n",
        "\t# calculate precision\n",
        "\tp = tp / (tp + fp + backend.epsilon())\n",
        "\t# calculate recall\n",
        "\tr = tp / (tp + fn + backend.epsilon())\n",
        "\t# calculate fbeta, averaged across each class\n",
        "\tbb = beta ** 2\n",
        "\tfbeta_score = backend.mean((1 + bb) * (p * r) / (bb * p + r + backend.epsilon()))\n",
        "\treturn fbeta_score"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SxDKB2cdEHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=Adam(0.0001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=[fbeta])"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlZfSNBGq0CQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "cec5d9bc-da90-4eae-89d7-39d4a6286fe8"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_14 (InputLayer)        [(None, 299, 299, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_resnet_v2 (Functio (None, 8, 8, 1536)        54336736  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_6 ( (None, 1536)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1024)              1573888   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 17)                17425     \n",
            "=================================================================\n",
            "Total params: 55,928,049\n",
            "Trainable params: 1,591,313\n",
            "Non-trainable params: 54,336,736\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4LiLAYHjGYQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "fa08ed61-9d92-4166-9303-e83fdab49895"
      },
      "source": [
        "train_steps_per_epoch = len(y_train) // 128\n",
        "print(train_steps_per_epoch)\n",
        "val_steps_per_epoch = len(y_val) // 128\n",
        "print(val_steps_per_epoch)"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "281\n",
            "35\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGDeAvgIiQNU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "69601f05-48ad-45b8-aa6b-ac5f820b4645"
      },
      "source": [
        "# Creating Callbacks \n",
        "checkpoint_best_path = '/content/drive/My Drive/Kaggle'\n",
        "\n",
        "checkpoint_best = ModelCheckpoint(filepath=checkpoint_best_path , save_weights_only=True,\n",
        "                                  save_best_only = True, verbose=1,save_freq='epoch', \n",
        "                                  monitor= 'val_fbeta', mode='max')\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=7,monitor='val_fbeta', mode='max')\n",
        "lrp = tf.keraslrp = tf.keras.callbacks.ReduceLROnPlateau(factor=0.25 , min_lr=0.0001)\n",
        "\n",
        "\n",
        "\n",
        "# fitting\n",
        "history = model.fit(\n",
        "            zx,\n",
        "            steps_per_epoch = train_steps_per_epoch, validation_data=valzx, \n",
        "            validation_steps=val_steps_per_epoch,\n",
        "            epochs = 40,\n",
        "            verbose = 2, callbacks=[early_stopping, lrp, checkpoint_best])"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "\n",
            "Epoch 00001: val_fbeta improved from -inf to 0.82857, saving model to /content/drive/My Drive/Kaggle\n",
            "281/281 - 408s - loss: 0.1699 - fbeta: 0.7790 - val_loss: 0.1293 - val_fbeta: 0.8286\n",
            "Epoch 2/40\n",
            "\n",
            "Epoch 00002: val_fbeta improved from 0.82857 to 0.84372, saving model to /content/drive/My Drive/Kaggle\n",
            "281/281 - 404s - loss: 0.1293 - fbeta: 0.8308 - val_loss: 0.1204 - val_fbeta: 0.8437\n",
            "Epoch 3/40\n",
            "\n",
            "Epoch 00003: val_fbeta improved from 0.84372 to 0.85428, saving model to /content/drive/My Drive/Kaggle\n",
            "281/281 - 405s - loss: 0.1217 - fbeta: 0.8420 - val_loss: 0.1160 - val_fbeta: 0.8543\n",
            "Epoch 4/40\n",
            "\n",
            "Epoch 00004: val_fbeta improved from 0.85428 to 0.85909, saving model to /content/drive/My Drive/Kaggle\n",
            "281/281 - 404s - loss: 0.1173 - fbeta: 0.8503 - val_loss: 0.1131 - val_fbeta: 0.8591\n",
            "Epoch 5/40\n",
            "\n",
            "Epoch 00005: val_fbeta improved from 0.85909 to 0.86250, saving model to /content/drive/My Drive/Kaggle\n",
            "281/281 - 404s - loss: 0.1143 - fbeta: 0.8542 - val_loss: 0.1110 - val_fbeta: 0.8625\n",
            "Epoch 6/40\n",
            "\n",
            "Epoch 00006: val_fbeta improved from 0.86250 to 0.86531, saving model to /content/drive/My Drive/Kaggle\n",
            "281/281 - 405s - loss: 0.1117 - fbeta: 0.8583 - val_loss: 0.1094 - val_fbeta: 0.8653\n",
            "Epoch 7/40\n",
            "\n",
            "Epoch 00007: val_fbeta improved from 0.86531 to 0.86746, saving model to /content/drive/My Drive/Kaggle\n",
            "281/281 - 404s - loss: 0.1097 - fbeta: 0.8616 - val_loss: 0.1079 - val_fbeta: 0.8675\n",
            "Epoch 8/40\n",
            "\n",
            "Epoch 00008: val_fbeta improved from 0.86746 to 0.86895, saving model to /content/drive/My Drive/Kaggle\n",
            "281/281 - 404s - loss: 0.1080 - fbeta: 0.8643 - val_loss: 0.1070 - val_fbeta: 0.8689\n",
            "Epoch 9/40\n",
            "\n",
            "Epoch 00009: val_fbeta improved from 0.86895 to 0.86988, saving model to /content/drive/My Drive/Kaggle\n",
            "281/281 - 404s - loss: 0.1065 - fbeta: 0.8658 - val_loss: 0.1060 - val_fbeta: 0.8699\n",
            "Epoch 10/40\n",
            "\n",
            "Epoch 00010: val_fbeta improved from 0.86988 to 0.87241, saving model to /content/drive/My Drive/Kaggle\n",
            "281/281 - 403s - loss: 0.1051 - fbeta: 0.8687 - val_loss: 0.1051 - val_fbeta: 0.8724\n",
            "Epoch 11/40\n",
            "\n",
            "Epoch 00011: val_fbeta improved from 0.87241 to 0.87479, saving model to /content/drive/My Drive/Kaggle\n",
            "281/281 - 403s - loss: 0.1039 - fbeta: 0.8695 - val_loss: 0.1045 - val_fbeta: 0.8748\n",
            "Epoch 12/40\n",
            "\n",
            "Epoch 00012: val_fbeta improved from 0.87479 to 0.87494, saving model to /content/drive/My Drive/Kaggle\n",
            "281/281 - 403s - loss: 0.1029 - fbeta: 0.8718 - val_loss: 0.1039 - val_fbeta: 0.8749\n",
            "Epoch 13/40\n",
            "\n",
            "Epoch 00013: val_fbeta improved from 0.87494 to 0.87649, saving model to /content/drive/My Drive/Kaggle\n",
            "281/281 - 404s - loss: 0.1019 - fbeta: 0.8730 - val_loss: 0.1034 - val_fbeta: 0.8765\n",
            "Epoch 14/40\n",
            "\n",
            "Epoch 00014: val_fbeta did not improve from 0.87649\n",
            "281/281 - 402s - loss: 0.1008 - fbeta: 0.8752 - val_loss: 0.1029 - val_fbeta: 0.8755\n",
            "Epoch 15/40\n",
            "\n",
            "Epoch 00015: val_fbeta improved from 0.87649 to 0.87749, saving model to /content/drive/My Drive/Kaggle\n",
            "281/281 - 403s - loss: 0.0999 - fbeta: 0.8762 - val_loss: 0.1025 - val_fbeta: 0.8775\n",
            "Epoch 16/40\n",
            "\n",
            "Epoch 00016: val_fbeta improved from 0.87749 to 0.87920, saving model to /content/drive/My Drive/Kaggle\n",
            "281/281 - 403s - loss: 0.0990 - fbeta: 0.8775 - val_loss: 0.1021 - val_fbeta: 0.8792\n",
            "Epoch 17/40\n",
            "\n",
            "Epoch 00017: val_fbeta did not improve from 0.87920\n",
            "281/281 - 402s - loss: 0.0982 - fbeta: 0.8787 - val_loss: 0.1019 - val_fbeta: 0.8783\n",
            "Epoch 18/40\n",
            "\n",
            "Epoch 00018: val_fbeta improved from 0.87920 to 0.88012, saving model to /content/drive/My Drive/Kaggle\n",
            "281/281 - 403s - loss: 0.0975 - fbeta: 0.8796 - val_loss: 0.1015 - val_fbeta: 0.8801\n",
            "Epoch 19/40\n",
            "\n",
            "Epoch 00019: val_fbeta improved from 0.88012 to 0.88035, saving model to /content/drive/My Drive/Kaggle\n",
            "281/281 - 403s - loss: 0.0965 - fbeta: 0.8807 - val_loss: 0.1014 - val_fbeta: 0.8803\n",
            "Epoch 20/40\n",
            "\n",
            "Epoch 00020: val_fbeta did not improve from 0.88035\n",
            "281/281 - 402s - loss: 0.0960 - fbeta: 0.8814 - val_loss: 0.1010 - val_fbeta: 0.8802\n",
            "Epoch 21/40\n",
            "\n",
            "Epoch 00021: val_fbeta improved from 0.88035 to 0.88182, saving model to /content/drive/My Drive/Kaggle\n",
            "281/281 - 403s - loss: 0.0954 - fbeta: 0.8823 - val_loss: 0.1008 - val_fbeta: 0.8818\n",
            "Epoch 22/40\n",
            "\n",
            "Epoch 00022: val_fbeta did not improve from 0.88182\n",
            "281/281 - 401s - loss: 0.0947 - fbeta: 0.8832 - val_loss: 0.1008 - val_fbeta: 0.8816\n",
            "Epoch 23/40\n",
            "\n",
            "Epoch 00023: val_fbeta did not improve from 0.88182\n",
            "281/281 - 402s - loss: 0.0939 - fbeta: 0.8840 - val_loss: 0.1006 - val_fbeta: 0.8812\n",
            "Epoch 24/40\n",
            "\n",
            "Epoch 00024: val_fbeta improved from 0.88182 to 0.88218, saving model to /content/drive/My Drive/Kaggle\n",
            "281/281 - 403s - loss: 0.0936 - fbeta: 0.8848 - val_loss: 0.1004 - val_fbeta: 0.8822\n",
            "Epoch 25/40\n",
            "\n",
            "Epoch 00025: val_fbeta did not improve from 0.88218\n",
            "281/281 - 402s - loss: 0.0930 - fbeta: 0.8853 - val_loss: 0.1005 - val_fbeta: 0.8815\n",
            "Epoch 26/40\n",
            "\n",
            "Epoch 00026: val_fbeta improved from 0.88218 to 0.88361, saving model to /content/drive/My Drive/Kaggle\n",
            "281/281 - 404s - loss: 0.0922 - fbeta: 0.8864 - val_loss: 0.1003 - val_fbeta: 0.8836\n",
            "Epoch 27/40\n",
            "\n",
            "Epoch 00027: val_fbeta did not improve from 0.88361\n",
            "281/281 - 402s - loss: 0.0916 - fbeta: 0.8869 - val_loss: 0.1000 - val_fbeta: 0.8830\n",
            "Epoch 28/40\n",
            "\n",
            "Epoch 00028: val_fbeta did not improve from 0.88361\n",
            "281/281 - 402s - loss: 0.0911 - fbeta: 0.8883 - val_loss: 0.1001 - val_fbeta: 0.8829\n",
            "Epoch 29/40\n",
            "\n",
            "Epoch 00029: val_fbeta improved from 0.88361 to 0.88364, saving model to /content/drive/My Drive/Kaggle\n",
            "281/281 - 403s - loss: 0.0907 - fbeta: 0.8886 - val_loss: 0.0999 - val_fbeta: 0.8836\n",
            "Epoch 30/40\n",
            "\n",
            "Epoch 00030: val_fbeta improved from 0.88364 to 0.88449, saving model to /content/drive/My Drive/Kaggle\n",
            "281/281 - 403s - loss: 0.0901 - fbeta: 0.8889 - val_loss: 0.0999 - val_fbeta: 0.8845\n",
            "Epoch 31/40\n",
            "\n",
            "Epoch 00031: val_fbeta did not improve from 0.88449\n",
            "281/281 - 402s - loss: 0.0896 - fbeta: 0.8899 - val_loss: 0.0997 - val_fbeta: 0.8840\n",
            "Epoch 32/40\n",
            "\n",
            "Epoch 00032: val_fbeta did not improve from 0.88449\n",
            "281/281 - 402s - loss: 0.0890 - fbeta: 0.8898 - val_loss: 0.0996 - val_fbeta: 0.8839\n",
            "Epoch 33/40\n",
            "\n",
            "Epoch 00033: val_fbeta improved from 0.88449 to 0.88533, saving model to /content/drive/My Drive/Kaggle\n",
            "281/281 - 404s - loss: 0.0886 - fbeta: 0.8908 - val_loss: 0.0996 - val_fbeta: 0.8853\n",
            "Epoch 34/40\n",
            "\n",
            "Epoch 00034: val_fbeta did not improve from 0.88533\n",
            "281/281 - 402s - loss: 0.0880 - fbeta: 0.8920 - val_loss: 0.0996 - val_fbeta: 0.8851\n",
            "Epoch 35/40\n",
            "\n",
            "Epoch 00035: val_fbeta did not improve from 0.88533\n",
            "281/281 - 401s - loss: 0.0876 - fbeta: 0.8919 - val_loss: 0.0994 - val_fbeta: 0.8836\n",
            "Epoch 36/40\n",
            "\n",
            "Epoch 00036: val_fbeta did not improve from 0.88533\n",
            "281/281 - 402s - loss: 0.0869 - fbeta: 0.8930 - val_loss: 0.0996 - val_fbeta: 0.8846\n",
            "Epoch 37/40\n",
            "\n",
            "Epoch 00037: val_fbeta improved from 0.88533 to 0.88537, saving model to /content/drive/My Drive/Kaggle\n",
            "281/281 - 403s - loss: 0.0866 - fbeta: 0.8934 - val_loss: 0.0994 - val_fbeta: 0.8854\n",
            "Epoch 38/40\n",
            "\n",
            "Epoch 00038: val_fbeta did not improve from 0.88537\n",
            "281/281 - 402s - loss: 0.0861 - fbeta: 0.8942 - val_loss: 0.0995 - val_fbeta: 0.8848\n",
            "Epoch 39/40\n",
            "\n",
            "Epoch 00039: val_fbeta improved from 0.88537 to 0.88582, saving model to /content/drive/My Drive/Kaggle\n",
            "281/281 - 403s - loss: 0.0856 - fbeta: 0.8945 - val_loss: 0.0992 - val_fbeta: 0.8858\n",
            "Epoch 40/40\n",
            "\n",
            "Epoch 00040: val_fbeta improved from 0.88582 to 0.88595, saving model to /content/drive/My Drive/Kaggle\n",
            "281/281 - 403s - loss: 0.0853 - fbeta: 0.8951 - val_loss: 0.0994 - val_fbeta: 0.8859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZJHTxJ3p5kb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zx = get_generator_cyclic(train_data, y_train, batch_size=64)\n",
        "valzx = get_valgenerator_cyclic(val_data, y_val, batch_size=64)"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQMtSWmzp6LD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d3d37aff-1802-426e-d07b-800deaac02f2"
      },
      "source": [
        "train_steps_per_epoch = len(y_train) // 64\n",
        "print(train_steps_per_epoch)\n",
        "val_steps_per_epoch = len(y_val) // 64\n",
        "print(val_steps_per_epoch)"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "562\n",
            "70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzUdmw7Fjp09",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "78d08647-0289-4def-c7ba-6b0b54561cac"
      },
      "source": [
        "# fine-tuning\n",
        "\n",
        "base_model.trainable = True\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),  # Very low learning rate\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=[fbeta])\n",
        "\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
        "lrp = tf.keraslrp = tf.keras.callbacks.ReduceLROnPlateau(factor=0.2)\n",
        "\n",
        "history = model.fit(\n",
        "            zx,\n",
        "            steps_per_epoch = train_steps_per_epoch, validation_data=valzx, \n",
        "            validation_steps=val_steps_per_epoch,\n",
        "            epochs = 2,\n",
        "            verbose = 2, callbacks=[early_stopping, lrp])"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "562/562 - 1287s - loss: 0.0853 - fbeta: 0.8976 - val_loss: 0.0932 - val_fbeta: 0.8917\n",
            "Epoch 2/2\n",
            "562/562 - 1286s - loss: 0.0746 - fbeta: 0.9109 - val_loss: 0.0935 - val_fbeta: 0.8946\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YuAVin4jXyD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "b369a28c-a81f-45f6-df00-3fa2df93211b"
      },
      "source": [
        "p_tes1 = model.predict(testzz1, verbose=1, steps=477)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  2/477 [..............................] - ETA: 4:49WARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.2621s vs `on_predict_batch_end` time: 0.9651s). Check your callbacks.\n",
            "477/477 [==============================] - 608s 1s/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnxNz5roTLzR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4b822849-ca36-4d5d-b3fc-b52aadfbff95"
      },
      "source": [
        "p_tes1.shape"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(61056, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGXkrLBrBnfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating an infinite looping generator for my test set offset\n",
        "\n",
        "def get_test3_generator_cyclic(labels, batch_size=1):\n",
        "  while True:\n",
        "    for ni in range(len(df_test['image_name'].iloc[40576:40669])//batch_size):\n",
        "      sa = []\n",
        "      for w in df_test['image_name'].iloc[40576:40669][ni*batch_size:(ni+1)*batch_size]:\n",
        "        img2 = cv2.imread('/content/planet/planet/test-jpg/{}.jpg'.format(w))\n",
        "        sa.append(cv2.resize(img2, (299,299)))      \n",
        "      cds = np.array(sa, np.float32)/255.\n",
        "      yield (cds)\n",
        "      sa = []\n",
        "\n",
        "\n",
        "def get_test4_generator_cyclic(labels, batch_size=1):\n",
        "  while True:\n",
        "    for ni in range(len(df_test['image_name'].iloc[61149:61191])//batch_size):\n",
        "      sa = []\n",
        "      for w in df_test['image_name'].iloc[61149:61191][ni*batch_size:(ni+1)*batch_size]:\n",
        "        img2 = cv2.imread('/content/test-jpg-additional/test-jpg-additional/{}.jpg'.format(w))\n",
        "        sa.append(cv2.resize(img2, (299,299)))      \n",
        "      cds = np.array(sa, np.float32)/255.\n",
        "      yield (cds)\n",
        "      sa = []"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJhfY6EOIYvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testzz3 = get_test3_generator_cyclic(df_test, batch_size=31)\n",
        "testzz4 = get_test4_generator_cyclic(df_test, batch_size=7)"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWznMkhLIsmM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "207aa14e-1c18-4414-be0c-35514968993b"
      },
      "source": [
        "p_tes3 = model.predict(testzz3, verbose=1, steps=3)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/3 [===================>..........] - ETA: 0sWARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0648s vs `on_predict_batch_end` time: 0.2506s). Check your callbacks.\n",
            "3/3 [==============================] - 1s 215ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nuhvRuvI1ts",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "df43a463-7b87-4fbe-83a0-202a59ae51b6"
      },
      "source": [
        "p_tes3.shape"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(93, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZcAyqPnI8Yw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "1ef01639-1a97-4329-ee58-ef189e829730"
      },
      "source": [
        "p_tes4 = model.predict(testzz4, verbose=1, steps=6)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/6 [====>.........................] - ETA: 0sWARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0266s vs `on_predict_batch_end` time: 0.0592s). Check your callbacks.\n",
            "6/6 [==============================] - 0s 72ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XyakuuBJGH7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f8db6906-979f-4d45-944c-6dc1d3308a35"
      },
      "source": [
        "p_tes4.shape"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T4H8SrfJOi9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test = []\n",
        "y_test.append(p_tes1)\n",
        "\n",
        "result = np.array(y_test[0])\n",
        "result = pd.DataFrame(result, columns=labels)"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2813XAcMQ2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test3 = []\n",
        "y_test3.append(p_tes3)\n",
        "\n",
        "result3 = np.array(y_test3[0])\n",
        "result3 = pd.DataFrame(result3, columns=labels)"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oqqeDasOCsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test4 = []\n",
        "y_test4.append(p_tes4)\n",
        "\n",
        "result4 = np.array(y_test4[0])\n",
        "result4 = pd.DataFrame(result4, columns=labels)"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "647cJFLvOLu1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5da8968d-a6ad-4323-9d51-4fa3bb34c976"
      },
      "source": [
        "preds4 = []\n",
        "\n",
        "for i in tqdm(range(result4.shape[0]), miniters=1000):\n",
        "    a = result4.iloc[[i]]\n",
        "    a = a.apply(lambda x: x > 0.2, axis=1)\n",
        "    a = a.transpose()\n",
        "    a = a.loc[a[i] == True]\n",
        "    ' '.join(list(a.index))\n",
        "    preds4.append(' '.join(list(a.index)))"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 42/42 [00:00<00:00, 302.24it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck3yzUvcMfrH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d3c36c78-1cc9-4c0c-8fd7-7f2c9ccffd5e"
      },
      "source": [
        "preds3 = []\n",
        "\n",
        "for i in tqdm(range(result3.shape[0]), miniters=1000):\n",
        "    a = result3.iloc[[i]]\n",
        "    a = a.apply(lambda x: x > 0.2, axis=1)\n",
        "    a = a.transpose()\n",
        "    a = a.loc[a[i] == True]\n",
        "    ' '.join(list(a.index))\n",
        "    preds3.append(' '.join(list(a.index)))"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 93/93 [00:00<00:00, 363.85it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46Ji9ydzJ7Jx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "df137e20-1b83-4b11-e940-f4c4e63573b9"
      },
      "source": [
        "preds = []\n",
        "\n",
        "for i in tqdm(range(result.shape[0]), miniters=1000):\n",
        "    a = result.iloc[[i]]\n",
        "    a = a.apply(lambda x: x > 0.2, axis=1)\n",
        "    a = a.transpose()\n",
        "    a = a.loc[a[i] == True]\n",
        "    ' '.join(list(a.index))\n",
        "    preds.append(' '.join(list(a.index)))"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 61056/61056 [02:39<00:00, 383.22it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rlm6_spfLLij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fist_df = pd.DataFrame(df_test['image_name'][:40576])\n",
        "fist_df['tags'] = preds[:40576]"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VY_1BQlLozw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fist_df3 = pd.DataFrame(df_test['image_name'][40576:40669]).reset_index(drop=True)\n",
        "fist_df3['tags'] = preds3[:]"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ4_suvYM6QI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fist_dfmid = pd.DataFrame(df_test['image_name'][40669:61149])\n",
        "fist_dfmid['tags'] = preds[40576:]"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3kTuRRgOTjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fist_df4 = pd.DataFrame(df_test['image_name'][61149:])\n",
        "fist_df4['tags'] = preds4[:]"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OB3T4cWOis_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fist_df5 = fist_df.append(fist_df3).append(fist_dfmid).append(fist_df4)\n",
        "fist_df5 = fist_df5.reset_index(drop=True)"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PcvwPaOPACs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "dbbfae72-3b13-4c51-bdeb-238500af4d03"
      },
      "source": [
        "fist_df5.head(5)"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_0</td>\n",
              "      <td>primary clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_1</td>\n",
              "      <td>primary clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_2</td>\n",
              "      <td>partly_cloudy primary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_3</td>\n",
              "      <td>agriculture cultivation primary clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_4</td>\n",
              "      <td>partly_cloudy cloudy primary</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  image_name                                   tags\n",
              "0     test_0                          primary clear\n",
              "1     test_1                          primary clear\n",
              "2     test_2                  partly_cloudy primary\n",
              "3     test_3  agriculture cultivation primary clear\n",
              "4     test_4           partly_cloudy cloudy primary"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1o9v8p9KKpt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fist_df5.to_csv('newsplanetsubmission2.csv', index=False)"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzAV_v2H0eqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}